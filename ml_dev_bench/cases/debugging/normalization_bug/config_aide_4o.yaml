# Core evaluation settings
num_runs: 1
fail_fast: false
log_level: "INFO"
output_dir: "./results"
workspace_dir: "./ml_dev_bench/cases/debugging/normalization_bug/setup_workspace"
langchain_project: "ml-dev-bench-evaluation-normalization-debug"
clone_workspace: true  # clones workspace to a temporary directory

# Task package imports
task_packages:
  - "ml_dev_bench.cases.debugging.normalization_bug"

# Agent configuration
agent_packages:
  - "agents.aide_ml_agent"

agent:
  id: "aide_ml_agent"
  model_name: "gpt-4o"

# Task configurations
tasks:
  - id: "normalization_bug"
