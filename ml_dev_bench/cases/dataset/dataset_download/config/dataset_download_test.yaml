# Core evaluation settings
num_runs: 1
fail_fast: false
log_level: "INFO"
output_dir: "./results"
workspace_dir: "./test_workspace"
langchain_project: "ml-dev-bench-evaluation-dataset-download"

# Task package imports
task_packages:
  - "ml_dev_bench.cases.dataset.dataset_download"

# Agent configuration
agent_packages:
  - "agents.react_agent"

# agent_packages:
#   - "agents.aide_ml_agent"

# Agent configuration
agent:
  id: "simple_react"
  # model_name: "gpt-4o-mini"
  model_name: "anthropic/claude-3-5-sonnet-20241022"
# agent:
#   id: "aide_ml_agent"
#   model_name: "gpt-4o-mini"

# Task configurations
tasks:
  - id: "dataset_download"
