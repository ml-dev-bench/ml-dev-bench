# Core evaluation settings
num_runs: 1
fail_fast: false
log_level: "INFO"
output_dir: "./results"
workspace_dir: "/workspace"
langchain_project: "ml-dev-bench-evaluation-dataset-download"

# Task package imports
task_packages:
  - "ml_dev_bench.cases.dataset.dataset_download"

# Agent configuration
agent_packages:
  - "agents.openhands_agent"

# Agent configuration
agent:
  id: "openhands_agent"
  model_name: "anthropic/claude-3-5-sonnet-20241022"


# Task configurations
tasks:
  - id: "dataset_download"



# Agent configuration
agent_packages:
  - "agents.openhands_agent"

# Agent configuration
agent:
  id: "openhands_agent"
  model_name: "anthropic/claude-3-5-sonnet-20241022"
